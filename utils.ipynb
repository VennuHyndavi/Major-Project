{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "def file_to_wordset(filename):\n",
    "    ''' Converts a file with a word per line to a Python set '''\n",
    "    words = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            words.append(line.strip())\n",
    "    return set(words)\n",
    "\n",
    "\n",
    "def write_status(i, total):\n",
    "    ''' Writes status of a process to console '''\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write('Processing %d/%d' % (i, total))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def save_results_to_csv(results, csv_file):\n",
    "    ''' Save list of type [(tweet_id, positive)] to csv in Kaggle format '''\n",
    "    with open(csv_file, 'w') as csv:\n",
    "        csv.write('id,prediction\\n')\n",
    "        for tweet_id, pred in results:\n",
    "            csv.write(tweet_id)\n",
    "            csv.write(',')\n",
    "            csv.write(str(pred))\n",
    "            csv.write('\\n')\n",
    "\n",
    "\n",
    "def top_n_words(pkl_file_name, N, shift=0):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of form {word:rank} of top N words from a pickle\n",
    "    file which has a nltk FreqDist object generated by stats.py\n",
    "    Args:\n",
    "        pkl_file_name (str): Name of pickle file\n",
    "        N (int): The number of words to get\n",
    "        shift: amount to shift the rank from 0.\n",
    "    Returns:\n",
    "        dict: Of form {word:rank}\n",
    "    \"\"\"\n",
    "    with open(pkl_file_name, 'rb') as pkl_file:\n",
    "        freq_dist = pickle.load(pkl_file,encoding='utf-8')\n",
    "    most_common = freq_dist.most_common(N)\n",
    "    words = {p[0]: i + shift for i, p in enumerate(most_common)}\n",
    "    return words\n",
    "\n",
    "\n",
    "def top_n_bigrams(pkl_file_name, N, shift=0):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of form {bigram:rank} of top N bigrams from a pickle\n",
    "    file which has a Counter object generated by stats.py\n",
    "    Args:\n",
    "        pkl_file_name (str): Name of pickle file\n",
    "        N (int): The number of bigrams to get\n",
    "        shift: amount to shift the rank from 0.\n",
    "    Returns:\n",
    "        dict: Of form {bigram:rank}\n",
    "    \"\"\"\n",
    "    with open(pkl_file_name, 'rb') as pkl_file:\n",
    "        freq_dist = pickle.load(pkl_file)\n",
    "    most_common = freq_dist.most_common(N)\n",
    "    bigrams = {p[0]: i for i, p in enumerate(most_common)}\n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def split_data(tweets, validation_split=0.1):\n",
    "    \"\"\"Split the data into training and validation sets\n",
    "    Args:\n",
    "        tweets (list): list of tuples\n",
    "        validation_split (float, optional): validation split %\n",
    "    Returns:\n",
    "        (list, list): training-set, validation-set\n",
    "    \"\"\"\n",
    "    index = int((1 - validation_split) * len(tweets))\n",
    "    random.shuffle(tweets)\n",
    "    return tweets[:index], tweets[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
